# Generating simplicial cycles
This repository provides an implementation for methods described in [`Applying language models to algebraic topology: generating simplicial cycles using multi-labeling in Wu's formula`]() by K. Brilliantov, F. Pavutnitskiy, D. Pasechnyuk, and G. Magai.

## Problem description
There is a Wu formula (J. Wu, 2001) for the homotopy groups of the two-dimensional sphere:
$$\pi_n(S^2) = \frac{R_0 \cap ... \cap R_{n-1}}{[[R_0, ..., R_n]]},$$
where $R_i = \langle x_i \rangle \subset F$ is a subgroup of free group $F$ generated by $x_i$ ( $i=1, ..., n$ ), $R_0 = \langle x_1 x_2 ... x_n \rangle \subset F$, and $[[R_0, ..., R_n]] = \Pi_{\pi \in S_n} [R_{\pi(0)}, ..., R_{\pi(n)}]$ is a symmetric commutant. Following this formula, we're trying to solve the problem of sampling elements from the homotopy group, represented by some elements of a free group $F$, which can be expressed by words in the alphabet $\{ x_1, ..., x_n, x_1^{-1}, ..., x_n^{-1} \}$, pretty comfortable object to apply computational algorithms. At the same time, sampling elements from $R_i$ (checking that element is in $R_i$) is a relatively simple procedure. It turns out to be significantly difficult to sample elements from the intersection of $R_i$'s (formula's numerator), and to check if they are in symmetric commutant (formula's denominator); there is no explicit algorithm for these problems. We propose several approximate algorithms, using a wide variety of approaches, from optimization theory and application of neural networks to NLP problems.

## Proposed approaches.
- `random-search`. We sample from incomplete intersections of $R_i$ s and test whether the sampled word is from the complete intersection.
- `evolutionary`. Using $(1+1)$-evolutionary algorithm, we search words to optimize the approximate distance to the intersection of subgroups $\Sigma_{i=0}^{n} d(x, R_i)$, where $d(x, R_i)$ is the length of the reduced word after substitution $x_i \to e$ or $x_1 \to x_{n-1}^{-1} \dots x_2^{-1}$
- `greedy`. We iteratively append generators to a word to minimize the approximate distance to the intersection of $R_i$ s.
- `language-modeling`. We train transformers to learn the intersection of distributions of $R_i$ s. We developed several training procedures based on different usages of `multi-label`. `multi-label` is a binary array of length $n + 1$ where $i$ th position denotes whether the given word is contained in $R_i$ or not.
  - `Ignore`, we model the language of the union of various incomplete intersections.
  - `Mask`, we additionally mask parts of the model during training accordingly to `multi-label`
  - `Prompt`, we model the language of words prepended with their `multi-label`s as prompts.

## Installation
- install [`freegroup`](https://github.com/ml-in-algebraic-topology/freegroup) module
- run `python -m pip install -r requirements.txt`

